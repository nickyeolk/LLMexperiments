{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QnA over PDF\n",
    "Reference from https://www.youtube.com/watch?v=TLf90ipMzfE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.147-py3-none-any.whl (626 kB)\n",
      "     ---------------------------------------- 0.0/626.5 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/626.5 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/626.5 kB 262.6 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 41.0/626.5 kB 281.8 kB/s eta 0:00:03\n",
      "     ----- ------------------------------- 92.2/626.5 kB 479.1 kB/s eta 0:00:02\n",
      "     -------- --------------------------- 143.4/626.5 kB 610.6 kB/s eta 0:00:01\n",
      "     ------------- ---------------------- 235.5/626.5 kB 850.1 kB/s eta 0:00:01\n",
      "     ------------------------ ------------- 399.4/626.5 kB 1.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  614.4/626.5 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 626.5/626.5 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.7-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ----------- ---------------------------- 0.6/2.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.0/2.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.5/2.1 MB 12.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 12.3 MB/s eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 0.0/90.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 90.0/90.0 kB ? eta 0:00:00\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Collecting SQLAlchemy<2,>=1\n",
      "  Downloading SQLAlchemy-1.4.47-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.6/1.6 MB 50.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 50.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Collecting tqdm>=4.48.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "     ---------------------------------------- 0.0/319.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 319.8/319.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.1-cp310-cp310-win_amd64.whl (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.9/60.9 kB ? eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 0.0/49.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 49.1/49.1 kB ? eta 0:00:00\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-win_amd64.whl (192 kB)\n",
      "     ---------------------------------------- 0.0/192.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 192.2/192.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from tqdm>=4.48.0->langchain) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, tenacity, PyYAML, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, attrs, async-timeout, yarl, typing-inspect, SQLAlchemy, pydantic, marshmallow-enum, aiosignal, openapi-schema-pydantic, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed PyYAML-6.0 SQLAlchemy-1.4.47 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 greenlet-2.0.2 langchain-0.0.147 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 tenacity-8.2.2 tqdm-4.65.0 typing-extensions-4.5.0 typing-inspect-0.8.0 yarl-1.9.1\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.3-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/10.4 MB 217.9 kB/s eta 0:00:48\n",
      "     --------------------------------------- 0.1/10.4 MB 363.1 kB/s eta 0:00:29\n",
      "     --------------------------------------- 0.1/10.4 MB 403.5 kB/s eta 0:00:26\n",
      "      -------------------------------------- 0.2/10.4 MB 655.4 kB/s eta 0:00:16\n",
      "      -------------------------------------- 0.2/10.4 MB 765.3 kB/s eta 0:00:14\n",
      "     - -------------------------------------- 0.4/10.4 MB 1.1 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.5/10.4 MB 1.3 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 0.8/10.4 MB 1.9 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.1/10.4 MB 2.3 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 1.9/10.4 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 2.6/10.4 MB 4.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.7/10.4 MB 6.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.3/10.4 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.1/10.4 MB 9.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 8.7/10.4 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 9.0/10.4 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.5/10.4 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.4/10.4 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.4/10.4 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.4/10.4 MB 13.9 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 0.0/70.3 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/70.3 kB ? eta -:--:--\n",
      "     ---------------- --------------------- 30.7/70.3 kB 259.2 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 61.4/70.3 kB 409.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 70.3/70.3 kB 425.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from aiohttp->openai) (1.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\likkh\\miniconda3\\envs\\py310env\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.4\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/232.6 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 30.7/232.6 kB 220.2 kB/s eta 0:00:01\n",
      "     ------ ------------------------------ 41.0/232.6 kB 245.8 kB/s eta 0:00:01\n",
      "     ----------- ------------------------- 71.7/232.6 kB 359.3 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 143.4/232.6 kB 568.9 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 204.8/232.6 kB 692.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 232.6/232.6 kB 751.1 kB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install faiss-cpu\n",
    "!pip install openai\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./keys/openai.txt', 'r') as fp:\n",
    "    key = fp.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader('./pdf_docs/gpt4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text+=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = '\\n',\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Technical Report\n",
      "OpenAI\u0003\n",
      "Abstract\n",
      "We report the development of GPT-4, a large-scale, multimodal model which can\n",
      "accept image and text inputs and produce text outputs. While less capable than\n",
      "humans in many real-world scenarios, GPT-4 exhibits human-level performance\n",
      "on various professional and academic benchmarks, including passing a simulated\n",
      "bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-\n",
      "based model pre-trained to predict the next token in a document. The post-training\n",
      "alignment process results in improved performance on measures of factuality and\n",
      "adherence to desired behavior. A core component of this project was developing\n",
      "infrastructure and optimization methods that behave predictably across a wide\n",
      "range of scales. This allowed us to accurately predict some aspects of GPT-4’s\n",
      "performance based on models trained with no more than 1/1,000th the compute of\n",
      "GPT-4.\n",
      "1 Introduction \n",
      "----------------------------\n",
      " range of scales. This allowed us to accurately predict some aspects of GPT-4’s\n",
      "performance based on models trained with no more than 1/1,000th the compute of\n",
      "GPT-4.\n",
      "1 Introduction\n",
      "This technical report presents GPT-4, a large multimodal model capable of processing image and\n",
      "text inputs and producing text outputs. Such models are an important area of study as they have the\n",
      "potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n",
      "and machine translation. As such, they have been the subject of substantial interest and progress in\n",
      "recent years [1–34].\n",
      "One of the main goals of developing such models is to improve their ability to understand and generate\n",
      "natural language text, particularly in more complex and nuanced scenarios. To test its capabilities\n",
      "in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. In\n",
      "these evaluations it performs quite well and often outscores the vast majority of human test takers.\n"
     ]
    }
   ],
   "source": [
    "print(texts[0], '\\n----------------------------\\n', texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(ChatOpenAI(model_name='gpt-3.5-turbo'), chain_type = 'map_reduce', return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['There is information on accuracy in the given text. The text states that the accuracy for an earlier version was around 30%, but a newer version increased accuracy to around 60%. Additionally, Figure 8 shows the performance of GPT-4 on TruthfulQA, with accuracy shown on the y-axis.',\n",
       "  \"According to Figure 6, the accuracy of the model is shown on the y-axis, with higher being better. An accuracy of 1.0 means the model's answers are judged to be in agreement with human ideal responses for all questions in the evaluation. GPT-4 improves on the latest GPT-3.5 model by 19 percentage points, with significant gains across all topics. Additionally, GPT-4 makes progress on public benchmarks like TruthfulQA, which tests the model's ability to separate fact from an adversarially-selected set of incorrect statements. However, it is only slightly better at this task than GPT-3.5, but after RLHF post-training, large improvements are observed.\",\n",
       "  'The document mentions the performance of GPT-4 on TruthfulQA, and that accuracy is shown on the y-axis, with higher being better. It also states that GPT-4 significantly outperforms both GPT-3.5 and Askell et al [100]. However, without additional context, it is unclear which specific accuracy metric is being referred to.',\n",
       "  'According to the text, the model has high accuracy (Figure 1).'],\n",
       " 'output_text': \"The accuracy of the model varies depending on the version. According to the text, an earlier version had an accuracy of around 30%, while a newer version increased accuracy to around 60%. GPT-4 improves on the latest GPT-3.5 model by 19 percentage points, with significant gains across all topics. Additionally, GPT-4 makes progress on public benchmarks like TruthfulQA, which tests the model's ability to separate fact from an adversarially-selected set of incorrect statements. However, it is only slightly better at this task than GPT-3.5, but after RLHF post-training, large improvements are observed. Therefore, the accuracy of the model is not a fixed number and varies depending on the version and the specific metric being referred to.\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'How does the model do in accuracy?'\n",
    "docs = docsearch.similarity_search(query)\n",
    "# chain.run(input_documents = docs, question=query)\n",
    "chain({'input_documents' : docs, 'question':query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310env]",
   "language": "python",
   "name": "conda-env-py310env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
